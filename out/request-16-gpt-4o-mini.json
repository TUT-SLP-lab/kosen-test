{
  "model": "gpt-4o-mini",
  "output": "大規模言語モデル（LLM）がハルシネーションを起こしやすいプロンプトの特徴はいくつかあります。\n\n1. **不明確な指示**: プロンプトが曖昧で具体性に欠ける場合、モデルは文脈を誤解して適切でない情報を生成する可能性があります。\n\n2. **複雑なリクエスト**: 複数の異なるトピックや質問を一度に要求すると、モデルが正確な情報を見つけるのが難しくなり、誤った情報を提供することがあります。\n\n3. **フィクションや空想に基づくプロンプト**: ファンタジーやサイエンスフィクションに関連するプロンプトは、現実に基づく情報が求められる場面でハルシネーションを引き起こすことがあります。\n\n4. **稀な事例やニッチな情報**: あまり一般的ではないトピックやデータについて尋ねると、モデルは信頼できる情報源が少ないため、不正確な情報を生成しやすくなります。\n\n5. **曖昧な文脈**: 特定の状況や背景がない場合、モデルは文脈を適切に捉えられず、誤った結論を出すことがあります。\n\nこれらの要因を考慮に入れ、プロンプトを設計する際には具体的かつ明確な要求を心がけることが重要です。",
  "input": "LLMがハルシネーションを起こしやすいプロンプトはどのようなプロンプトですか？"
}